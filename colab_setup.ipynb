{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Scene Generation on Google Colab\n",
    "\n",
    "This notebook sets up and runs the autoregressive visual scene generation system on Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Setup Environment\n\n**IMPORTANT**: If you're re-running the notebook or get nested directories, run this first:"
  },
  {
   "cell_type": "code",
   "source": "# Clean up any existing setup (run this if you get nested directories)\nimport os\n\n# Go to content root\n%cd /content\n\n# Remove old directory if it exists\n!rm -rf visual-scene-generation\n\nprint(\"✅ Environment reset. Proceed to next cell.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 2. Clone Repository"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 3. Install Dependencies"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check GPU Availability"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 4. Check GPU Availability"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. (Optional) Mount Google Drive for Persistent Storage\n\n**Recommended**: Mount Drive to save your checkpoints permanently. If you skip this, checkpoints will be lost when the session ends!"
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Mount Google Drive for Persistent Storage\n\n**CRITICAL**: Run this to save checkpoints permanently!",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 5. Quick Test Run (Small Dataset)"
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Verify Checkpoint Setup\n\nRun this to check where checkpoints will be saved:",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Quick Test Run (Small Dataset)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Quick Test Run (Small Dataset)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 7. Full Training Run"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 8. Full Training Run"
  },
  {
   "cell_type": "markdown",
   "source": "## 9. Interactive Scene Generation",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 9. Visualize Training Results"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport os\nfrom models import AutoregressiveLanguageModel, SceneDecoder, CaptionNetwork\nfrom data_utils import SceneDescriptionDataset\nimport matplotlib.pyplot as plt\n\ndef load_models_from_checkpoint(checkpoint_path=None):\n    \"\"\"\n    Load trained models from checkpoint.\n    If no checkpoint specified, finds the latest one.\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # Find checkpoint if not specified\n    if checkpoint_path is None:\n        # Check both local and Drive paths\n        checkpoint_dirs = ['checkpoints', '/content/drive/MyDrive/visual-scene-generation/checkpoints']\n        checkpoint_path = None\n        \n        for checkpoint_dir in checkpoint_dirs:\n            if os.path.exists(checkpoint_dir):\n                checkpoints = sorted([f for f in os.listdir(checkpoint_dir) if f.endswith('.pt')])\n                if checkpoints:\n                    checkpoint_path = os.path.join(checkpoint_dir, checkpoints[-1])\n                    break\n        \n        if checkpoint_path is None:\n            print(\"❌ No checkpoint found! Train the model first.\")\n            return None, None, None, None, device\n    \n    print(f\"Loading checkpoint: {checkpoint_path}\")\n    \n    # Load checkpoint to get vocab size\n    checkpoint = torch.load(checkpoint_path, map_location=device)\n    \n    # We need to create a dataset to get vocab (or extract from checkpoint if saved)\n    # For now, recreate dataset - it will have same vocab if same seed\n    dataset = SceneDescriptionDataset(num_samples=1000, seed=42)\n    vocab_size = dataset.vocab_size\n    \n    print(f\"Vocabulary size: {vocab_size}\")\n    \n    # Initialize models with same architecture as training\n    ar_model = AutoregressiveLanguageModel(\n        vocab_size=vocab_size,\n        d_model=512,  # Use default or match your training config\n        n_heads=8,\n        n_layers=6\n    ).to(device)\n    \n    scene_decoder = SceneDecoder(\n        embedding_dim=512,\n        hidden_dim=256,\n        use_vae=True,\n        z_dim=128\n    ).to(device)\n    \n    caption_network = CaptionNetwork(\n        vocab_size=vocab_size,\n        embedding_dim=512,\n        hidden_dim=256\n    ).to(device)\n    \n    # Load state dicts\n    try:\n        ar_model.load_state_dict(checkpoint['models']['ar_model'])\n        scene_decoder.load_state_dict(checkpoint['models']['scene_decoder'])\n        caption_network.load_state_dict(checkpoint['models']['caption_network'])\n        \n        # Set to eval mode\n        ar_model.eval()\n        scene_decoder.eval()\n        caption_network.eval()\n        \n        print(f\"✅ Models loaded successfully from epoch {checkpoint['epoch']}\")\n        print(f\"   Training loss: {checkpoint['loss']:.4f}\")\n        \n    except Exception as e:\n        print(f\"❌ Error loading models: {e}\")\n        return None, None, None, None, device\n    \n    return ar_model, scene_decoder, caption_network, dataset, device\n\n# Load the models\nar_model, scene_decoder, caption_network, dataset, device = load_models_from_checkpoint()\n\nif ar_model is not None:\n    print(\"\\n✅ Ready for scene generation!\")\nelse:\n    print(\"\\n⚠️ Please train the model first before running generation.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10. Interactive Scene Generation",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Generate scene from your own custom text!\n# Change this to whatever you want:\ncustom_text = \"a tiny red sphere on the right\"\n\nif ar_model is not None:\n    print(f\"Generating scene for: '{custom_text}'\\n\")\n    scene, caption = generate_scene_from_text(\n        custom_text, \n        ar_model, \n        scene_decoder, \n        caption_network, \n        dataset, \n        device\n    )\nelse:\n    print(\"⚠️ Load models first (run cell 8)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Resume Training from Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for Colab\n",
    "\n",
    "1. **Enable GPU**: Go to Runtime → Change runtime type → Hardware accelerator → GPU\n",
    "2. **Prevent Disconnection**: Keep the tab active or use Colab Pro for longer sessions\n",
    "3. **Save Progress**: Regularly save checkpoints to Google Drive\n",
    "4. **Monitor Memory**: Use smaller batch sizes if you encounter OOM errors\n",
    "5. **Use Mixed Precision**: Add `--use_amp` flag for faster training with less memory"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "visual_scene_generation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}